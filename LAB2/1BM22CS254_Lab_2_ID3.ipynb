{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voZk9vS13pdh",
        "outputId": "c5876651-5ad3-4fc4-8d14-4500d02b130f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outlook\n",
            " └─ sunny\n",
            "    humidity\n",
            "     └─ high\n",
            "        → no\n",
            "     └─ normal\n",
            "        → yes\n",
            " └─ overcast\n",
            "    → yes\n",
            " └─ rainy\n",
            "    windy\n",
            "     └─ False\n",
            "        → yes\n",
            "     └─ True\n",
            "        → no\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Function to calculate entropy\n",
        "def entropy(y):\n",
        "    counts = Counter(y)\n",
        "    probabilities = [count / len(y) for count in counts.values()]\n",
        "    return -sum(p * math.log2(p) for p in probabilities)\n",
        "\n",
        "# Function to calculate information gain\n",
        "def information_gain(data, feature, target):\n",
        "    total_entropy = entropy(data[target])\n",
        "    values = data[feature].unique()\n",
        "    weighted_entropy = sum((len(data[data[feature] == v]) / len(data)) * entropy(data[data[feature] == v][target]) for v in values)\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "# Recursive ID3 algorithm to build the decision tree\n",
        "def id3(data, features, target):\n",
        "    # If all target values are the same, return the label\n",
        "    if len(set(data[target])) == 1:\n",
        "        return data[target].iloc[0]\n",
        "\n",
        "    # If no features left, return the most common label\n",
        "    if len(features) == 0:\n",
        "        return data[target].mode()[0]\n",
        "\n",
        "    # Choose the best feature based on information gain\n",
        "    gains = {feature: information_gain(data, feature, target) for feature in features}\n",
        "    best_feature = max(gains, key=gains.get)\n",
        "\n",
        "    # Create tree node\n",
        "    tree = {best_feature: {}}\n",
        "\n",
        "    # Split dataset and recurse for each value of the best feature\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]\n",
        "        remaining_features = [f for f in features if f != best_feature]\n",
        "        tree[best_feature][value] = id3(subset, remaining_features, target)\n",
        "\n",
        "    return tree\n",
        "\n",
        "# Function to print decision tree in a readable format\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if not isinstance(tree, dict):\n",
        "        print(indent + \"→ \" + str(tree))\n",
        "        return\n",
        "\n",
        "    for key, value in tree.items():\n",
        "        print(indent + str(key))\n",
        "        for sub_key, sub_tree in value.items():\n",
        "            print(indent + \" └─ \" + str(sub_key))\n",
        "            print_tree(sub_tree, indent + \"    \")\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/tennis.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Apply ID3 algorithm\n",
        "features = list(data.columns[:-1])  # All columns except the target\n",
        "target = 'play'\n",
        "decision_tree = id3(data, features, target)\n",
        "\n",
        "# Print the decision tree\n",
        "print_tree(decision_tree)"
      ]
    }
  ]
}